{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0081801-10ba-442b-b5fa-760f80f058f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbaijal/.local/lib/python3.6/site-packages/numba/core/errors.py:154: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from audio_proc_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadefa6-b9c5-46c6-bc34-4f9c1dc0a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier:\n",
    "    def __init__(self):\n",
    "        self.W =None # define model parameters here\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        z1 = np.exp(z)\n",
    "        return z1 / np.sum(z1, axis=0)\n",
    "    \n",
    "    def y_hat(self, X):\n",
    "        z = self.W @ X\n",
    "        return self.softmax(z)\n",
    "    \n",
    "    def cross_entropy_loss(self, y_pred, y ):\n",
    "        # y is of shape (3 x num_frames)\n",
    "        loss = -np.sum((np.log(y_pred) * y))\n",
    "        loss = loss / y.shape[1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        yhat = self.y_hat(X)\n",
    "        predicted = yhat.argmax(axis=0)\n",
    "        return predicted\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        loss_history = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            y_pred = self.y_hat(X)\n",
    "\n",
    "            grad = (y_pred - Y) @ X.T\n",
    "            N = X.shape[1]\n",
    "            grad = grad/N\n",
    "            \n",
    "            self.W = self.W - alpha * grad\n",
    "            \n",
    "            l = self.cross_entropy_loss(y_pred, Y)\n",
    "            loss_history.append(l)\n",
    "        return loss_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec859031-31de-440d-9064-56b3440b8261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.34985881]\n",
      " [2.71828183 1.34985881]\n",
      " [1.         1.4918247 ]]\n",
      "[[0.21194156 0.32204346]\n",
      " [0.57611688 0.32204346]\n",
      " [0.21194156 0.35591307]]\n",
      "[[0.         0.32204346]\n",
      " [0.57611688 0.        ]\n",
      " [0.         0.        ]]\n",
      "[0.32204346 0.57611688 0.        ]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[0,1,0], [0.3, 0.3, 0.4]]).T\n",
    "z1 = np.exp(a)\n",
    "print(z1)\n",
    "s = z1 / np.sum(z1, axis=0)\n",
    "t = np.array([[0,1,0], [1,0,0]]).T\n",
    "print(s)\n",
    "b = s*t\n",
    "print(b)\n",
    "print(np.sum(b, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bda4f4c-18ea-4b45-953d-1eb910cfb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs= 16000\n",
    "n_mfcc = 20\n",
    "\n",
    "# Read audio\n",
    "x_music = readDir('music_speech/music_wav', Fs)    #change it as per your directory\n",
    "x_speech = readDir('music_speech/speech_wav', Fs)  #change it as per your directory\n",
    "x_silence = readDir('music_speech/silence_wav', Fs)\n",
    "X = np.concatenate((x_music, x_speech, x_silence))\n",
    "\n",
    "# Create labels\n",
    "y_music = np.array([[1,0,0]]*len(x_music))\n",
    "y_speech = np.array([[0,1,0]]*len(x_speech))\n",
    "y_silence = np.array([[0,0,1]]*len(x_silence))\n",
    "Y = np.concatenate((y_music, y_speech, y_silence))\n",
    "\n",
    "X_train, y_train, X_test, y_test = splitData(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203beff7-b803-4cc7-bada-6a012c711f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = audio2mfcc(X_train, n_mfcc, Fs)    # x_train: (Nclips, N_mfcc, N_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a01b60-fc79-4b7f-bee7-b4fb5d111586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 20, 313)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x_train[0]\n",
    "x2 = x_train[1]\n",
    "x1 = x1.T\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ca9cb3-f91e-4e66-b926-7ff312a38583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5],\n",
       "       [2, 3, 6],\n",
       "       [3, 4, 7]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([1,2,3])\n",
    "a2 = np.array([2,3,4])\n",
    "a3 = np.array([5,6,7])\n",
    "a = []\n",
    "a.append(a1)\n",
    "a.append(a2)\n",
    "a.append(a3)\n",
    "ans = np.vstack(a)\n",
    "ans.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513a7181-4a9e-463a-ba9d-56c232cb3f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((y_train[0].reshape(-1,1), y_train[1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1103e55-4fef-48d0-9938-41863fc329d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 160000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0785db9c-3cf1-4b0c-91f1-6d94e14b3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_data(X, Y):\n",
    "    x = []\n",
    "    y = []\n",
    "    # X is of shape (num_clips x num_features x num_frames)\n",
    "    for i in range(X.shape[0]):\n",
    "        x1 = X[0].T\n",
    "        for j in range(x1.shape[0]):\n",
    "            x.append(x1[j])\n",
    "            y.append(Y[i])\n",
    "    \n",
    "    x = np.vstack(x)\n",
    "    y = np.vstack(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd209d9-62ce-420d-ae44-b094f50fd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = unwrap_data(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
