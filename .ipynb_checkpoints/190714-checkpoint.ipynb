{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE603 Coding Assignment\n",
    "- Use python3\n",
    "- Submit your \"rendered\" ipynb, i.e., with outputs of codes (plots and printed values) visible below\n",
    "- Do not change the return variables, as the evaluation is done by test cases based on the variables specified. Only add your code at \"### WRITE YOUR CODE HERE\"\n",
    "- Use only numpy and librosa library for computing and signal processing, no other package allowed\n",
    "- If you are using your mobile phone, you can use colab.research.google.com for coding\n",
    "- Do not define multiple functions using same name. We will be using eval.py to auto evaluate your codes. Please check with sample test cases before submitting. We will share the evaluation test cases with you after the submission deadline.\n",
    "- While submitting this file, change file name from 'YourRollNo.ipynb' to your actual roll no (Eg. 18204279.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def readDir(dirname, Fs = 22050):\n",
    "    \n",
    "    '''\n",
    "    Each audio clip should be upto 10s long; split larger audio files into many clips (non-overlapping) \n",
    "\n",
    "    Use load_audio(file) \n",
    "    \n",
    "    Inputs: \n",
    "        dirname: (str) directory name\n",
    "        Fs: (int) sampling rate\n",
    "    Output: \n",
    "        x: np arrays of shape (Nclips, Nsamples) Nsamples correspond to 10s length. Use zero-padding for shorter clips.\n",
    "    '''  \n",
    "\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "    required_duration = 10\n",
    "    x = np.zeros(required_duration*Fs)\n",
    "    \n",
    "    for path in glob.iglob(f'{dirname}/*.wav'):\n",
    "        audio = load_audio(path, Fs)\n",
    "        num_per_clip = Fs*required_duration   # Number of point samples for 10s audio clip\n",
    "        N = (int)(audio.shape[0]/num_per_clip)\n",
    "        for i in range(0, N):\n",
    "            x = np.vstack((x, audio[i*num_per_clip : (i+1)*num_per_clip]))\n",
    "         \n",
    "        # Last audio sample must be zero padded\n",
    "        if(audio.shape[0]%num_per_clip != 0):\n",
    "            seq = audio[N*num_per_clip:]\n",
    "            seq = librosa.util.fix_length(seq, required_duration*Fs)\n",
    "            x = np.vstack((x, seq))\n",
    "\n",
    "    # We need to skip the initial zero array which was added for convenience\n",
    "    x = x[1:, :]           # Nclips x Nsamples\n",
    "    \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename, Fs = 22050):\n",
    "    '''\n",
    "    Inputs: \n",
    "        filename: (str) filename\n",
    "        Fs: (int) sampling rate\n",
    "    Output: \n",
    "        x: 1D np array \n",
    "    '''\n",
    "    \n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    x, sr = librosa.load(filename, sr=Fs)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, t, testFraction=0.2, randomize = False):\n",
    "    \"\"\"\n",
    "    Split the data randomly into training and test sets\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: (np array of len Nclips) input feature vectors\n",
    "        t: (np array of len Nclips) targets; one hot vectors\n",
    "        testFraction: (float) Nclips_test = testFraction * Nclips\n",
    "    Outputs:\n",
    "        X_train: training set\n",
    "        X_test: test set\n",
    "        t_train: training labels\n",
    "        t_test: test labels\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "    np.random.seed(0)\n",
    "    test_size = (int)(testFraction * X.shape[0])\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    training_index, test_index = indices[:X.shape[0] - test_size], indices[X.shape[0] - test_size:]\n",
    "    X_train, t_train = X[training_index, :], t[training_index, :]\n",
    "    X_test, t_test = X[test_index, :], t[test_index, :]\n",
    "\n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2mfcc(x, n_mfcc = 13, Fs = 22050):\n",
    "    \n",
    "    '''\n",
    "    Compute Mel-frequency cepstral coefficients (MFCCs)\n",
    "    Inputs:\n",
    "        x: np array of shape (Nclips,)\n",
    "        Fs: (int) sampling rate\n",
    "        n_mfcc: (int) number of MFCC features\n",
    "    Output:\n",
    "        X: (np array) MFCC sequence\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    X = []\n",
    "    for i in range(len(x)):\n",
    "        mfccs = librosa.feature.mfcc(y=x[i], sr=Fs, n_mfcc=n_mfcc, hop_length=512)\n",
    "        X.append(mfccs)\n",
    "            \n",
    "#     X = np.concatenate(X)\n",
    "    X = np.stack(X, axis=0) # 3D array => Nsample 2D arrays of MFCCs\n",
    "#     print(\"mfcc feat : \", X.shape)\n",
    "\n",
    "    return X                # (Nclips, N_mfcc, N_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier: \n",
    "    '''\n",
    "    Create a linear classifier to classify each frame\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.W = np.random.rand(21).reshape((21,1)) # define model parameters here\n",
    "    \n",
    "    def sigmoid(self, h):\n",
    "        return 1/(1 + np.exp(-h))\n",
    "    \n",
    "    def loss_function(self, X, y): \n",
    "        # X : N x D\n",
    "        # y : N x 1\n",
    "        z = np.dot(X, self.W)\n",
    "        pred_1 = y * np.log(self.sigmoid(z))\n",
    "        pred_0 = (1 - y) * np.log(1 - self.sigmoid(z))\n",
    "        return -np.sum(pred_1 + pred_0) / len(X)\n",
    "        \n",
    "    def train(self,x_train, y_train):\n",
    "        '''\n",
    "        Train the linear classifier\n",
    "        Inputs:\n",
    "            x_train: training set\n",
    "            y_train: training labels\n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "        X_speech = []\n",
    "        X_music = []\n",
    "        y = []\n",
    "        # Segregate music and speech examples\n",
    "        # each 10s sample is converted into a 2d array of size (13, 431) (MFCC)\n",
    "        \n",
    "        y_music = []\n",
    "        y_speech = []\n",
    "        for i in range(len(x_train)):\n",
    "            if y_train[i][0]==1:\n",
    "                y_music = y_music + [1]*x_train[i].shape[1]\n",
    "                if len(X_music) == 0:\n",
    "                    X_music = x_train[i]     # Nmfcc x 431\n",
    "                else:\n",
    "                    X_music = np.concatenate((X_music, x_train[i]), axis=1)\n",
    "            else:\n",
    "                y_speech = y_speech + [0]*x_train[i].shape[1]\n",
    "                if len(X_speech) == 0:\n",
    "                    X_speech = x_train[i]\n",
    "                else:\n",
    "                    X_speech = np.concatenate((X_speech, x_train[i]), axis=1)\n",
    "        \n",
    "        X_temp = np.concatenate((X_music, X_speech), axis=1) # Nmfcc x total no. of frames\n",
    "        X_temp = (X_temp - np.mean(X_temp, axis=1,keepdims=True ))/np.std(X_temp, axis=1, keepdims=True) # standardize\n",
    "        y = y_music + y_speech\n",
    "        \n",
    "        '''Logistic Regression Training'''\n",
    "        t = np.array(y)\n",
    "        t = t.reshape(t.shape[0], 1)\n",
    "#         print(t.shape)\n",
    "#         print(X_temp.shape)\n",
    "\n",
    "        '''Add row of 1 in order to incorporate bias term'''\n",
    "        one_row = np.ones((1,X_temp.shape[1]))\n",
    "        X_temp = np.vstack((one_row, X_temp))\n",
    "        X = X_temp.T                         # N x D\n",
    "#         print(X.shape)\n",
    "        \n",
    "        '''Random weights initialization'''\n",
    "        self.W = np.random.rand((X.shape[1])).reshape((X.shape[1],1))\n",
    "        \n",
    "        loss = []\n",
    "        lr = 0.1\n",
    "        N = X.shape[0]\n",
    "        for i in range(300):\n",
    "            y_pred = self.sigmoid(np.dot(X, self.W))\n",
    "            grad = np.dot(X.T, y_pred - t)/N\n",
    "            self.W -= lr * grad\n",
    "            l = self.loss_function(X,t)\n",
    "            loss.append(l)\n",
    "            if (i+1)%50 == 0:\n",
    "                print(\"Epoch %d : %f\"% (i+1, l))\n",
    " \n",
    "        plt.plot(loss)\n",
    "#         print(self.W)\n",
    "        return True\n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        '''\n",
    "        Save the trained model on local disk\n",
    "        Input:\n",
    "            save_path: location at which model is to be saved\n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "#         file = open(save_path, \"w+\")\n",
    "#         print(self.W.shape[0])\n",
    "#         for i in range(self.W.shape[0]):\n",
    "#             file.write(str(self.W[i][0]))\n",
    "#             file.write(\"\\n\")    \n",
    "#         file.close()\n",
    "        np.save(save_path, self.W)\n",
    "        return True\n",
    "    \n",
    "    def load_model(self, load_path):\n",
    "        '''\n",
    "        Save the trained model on local disk\n",
    "        Input:\n",
    "            load_path: location from which model is to be loaded\n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "#         file = open(load_path, \"r\")\n",
    "#         lines = file.readlines()\n",
    "#         self.W = np.zeros((len(lines), 1))\n",
    "#         for i in range(len(lines)):\n",
    "#             self.W[i][0] = float(lines[i])\n",
    "#         print(self.W)\n",
    "        self.W = np.load(load_path)\n",
    "        return None\n",
    "\n",
    "\n",
    "    \n",
    "    def predict_framewise(self,x_test):\n",
    "        '''\n",
    "        Framewise classification (speech or music)\n",
    "        Input:\n",
    "            x_test: test set\n",
    "        Output:\n",
    "            y_pred_framewise = framewise prediction\n",
    "        '''\n",
    "        \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        '''Perform Normalization'''\n",
    "        '''x_test shape : Nclips x Nmfcc x frame_per_clip'''\n",
    "        x = x_test[0] \n",
    "        for i in range(1, len(x_test)):\n",
    "            x = np.concatenate((x, x_test[i]), axis=1)\n",
    "        \n",
    "        x = (x - np.mean(x, axis=1, keepdims=True))/np.std(x, axis=1, keepdims=True) # Nmfcc x total_frames\n",
    "        \n",
    "        frames_per_sample = x_test[0].shape[1]\n",
    "        \n",
    "        '''Get original 3 shape back'''\n",
    "        x_t = []\n",
    "        for i in range(len(x_test)):\n",
    "            x_t.append(x[:, frames_per_sample*i:frames_per_sample*(i+1)])\n",
    "        \n",
    "        x_t = np.stack(x_t, axis=0)\n",
    "        x_test = x_t\n",
    "        \n",
    "        '''Start framewise prediction'''\n",
    "        y_pred_framewise = []\n",
    "        one_row = np.ones((1, x_test[0].shape[1]))\n",
    "        x_t = []\n",
    "        for i in range(len(x_test)):\n",
    "            a = np.vstack((one_row, x_test[i]))\n",
    "            x_t.append(np.vstack(a))\n",
    "        \n",
    "        x_t = np.stack(x_t, axis=0)\n",
    "        \n",
    "        for i in range(len(x_t)):\n",
    "            # using W.T . X instead of X . W : Just makes a difference in shape for convenience\n",
    "            pred = np.dot(self.W.T, x_t[i])\n",
    "            pred = self.sigmoid(pred)\n",
    "            pred = np.vstack((pred, pred)) # In order to match dimensions\n",
    "            y_pred_framewise.append(pred)\n",
    "        \n",
    "        y_pred_framewise = np.stack(y_pred_framewise, axis=0)\n",
    "#         print(\"y_pred_framewise : \", y_pred_framewise.shape)\n",
    "\n",
    "        return y_pred_framewise \n",
    "    \n",
    "    def predict_aggregate(self,y_pred_framewise):\n",
    "        '''\n",
    "        Aggregate frames to give a single class label (music or speech) to the entire audio file\n",
    "        Input:\n",
    "            y_pred_framewise = framewise prediction\n",
    "        Output:\n",
    "            y_hat = frame aggregate (one-hot vectors)\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        y_hat = []\n",
    "#         print('pred', y_pred_framewise.shape)\n",
    "        for i in range(y_pred_framewise.shape[0]):\n",
    "            frames_pred = y_pred_framewise[i][0].reshape((1,y_pred_framewise.shape[2]))\n",
    "            result = np.sum(frames_pred > 0.5 , axis = 1)\n",
    "#             print(result)\n",
    "            # Majority voting\n",
    "            if(result > (int)(y_pred_framewise.shape[2]/2)):\n",
    "                y_hat.append([1,0]) # Music\n",
    "            else:\n",
    "                y_hat.append([0,1]) # Speech\n",
    "        y_hat = np.stack(y_hat, axis=0)\n",
    "\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCM(y, y_hat):\n",
    "    '''\n",
    "    Compute confusion matrix to evaluate your model\n",
    "    Inputs:\n",
    "        y = labels \n",
    "        y_hat = predicted output\n",
    "    Output:\n",
    "        confusion matrix: confusion matrix\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "    #                True  \n",
    "    #           Speech |  Music\n",
    "    #          _________________\n",
    "    #    Speech|       |       |\n",
    "    # Pred     -----------------\n",
    "    #    Music |       |       |\n",
    "    #          -----------------\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    for i in range(y.shape[0]):\n",
    "        r = (int)(y_hat[i][0])\n",
    "        c = (int)(y[i][0])\n",
    "        confusion_matrix[r][c] += 1\n",
    "\n",
    "\n",
    "    return confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : 0.568942\n",
      "Epoch 100 : 0.532842\n",
      "Epoch 150 : 0.528627\n",
      "Epoch 200 : 0.527699\n",
      "Epoch 250 : 0.527437\n",
      "Epoch 300 : 0.527355\n",
      "[[31.  8.]\n",
      " [10. 27.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    # My parameters\n",
    "    Fs= 22050\n",
    "    n_mfcc = 13\n",
    "    \n",
    "    '''NOTE : The model has been trained on the GZTAN music_speech dataset \n",
    "        http://marsyas.info/downloads/datasets.html\n",
    "    '''\n",
    "    # Read audio\n",
    "    x_music = readDir('music_speech/music_wav', Fs)    #change it as per your directory\n",
    "    x_speech = readDir('music_speech/speech_wav', Fs)  #change it as per your directory\n",
    "    X = np.concatenate((x_music, x_speech))\n",
    "    \n",
    "    # Create labels\n",
    "    y_music = np.array([[1,0]]*len(x_music))\n",
    "    y_speech = np.array([[0,1]]*len(x_speech))\n",
    "    Y = np.concatenate((y_music, y_speech))\n",
    "    \n",
    "    \n",
    "    X_train, y_train, X_test, y_test = splitData(X, Y)\n",
    "    \n",
    "    # TRAINING \n",
    "    x_train = audio2mfcc(X_train, n_mfcc, Fs)    # x_train: (Nclips, N_mfcc, N_frames)\n",
    "    model = Classifier() \n",
    "    model.train(x_train, y_train)        # y_train: (Nclips, 2) -repeat it N_frames times inside the train\n",
    "    \n",
    "    # TESTING \n",
    "    x_test = audio2mfcc(X_test, n_mfcc, Fs) \n",
    "    y_pred = model.predict_framewise(x_test)   # y_predict: (Nclips, 2, N_frames)\n",
    "    y_hat = model.predict_aggregate(y_pred)    # y_hat: (Nclips, 2)\n",
    "\n",
    "   # EVALUATION METRICS \n",
    "    confusion_matrix = computeCM(y_test, y_hat) \n",
    "    print(confusion_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save_model(\"weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05167005]\n",
      " [ 1.15008408]\n",
      " [ 0.9413482 ]\n",
      " [ 0.55262241]\n",
      " [ 0.27489016]\n",
      " [-0.05209373]\n",
      " [ 0.29904284]\n",
      " [ 0.43035029]\n",
      " [-0.23228537]\n",
      " [ 0.35785071]\n",
      " [-0.12981565]\n",
      " [-0.13138317]\n",
      " [-0.11461311]\n",
      " [ 0.19534376]]\n"
     ]
    }
   ],
   "source": [
    "# M = Classifier()\n",
    "# M.load_model(\"weights.npy\")\n",
    "# print(M.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.  8.]\n",
      " [10. 27.]]\n"
     ]
    }
   ],
   "source": [
    "# y_pred = M.predict_framewise(x_test)   # y_predict: (Nclips, 2, N_frames)\n",
    "# y_hat = M.predict_aggregate(y_pred)    # y_hat: (Nclips, 2)\n",
    "\n",
    "# # # EVALUATION METRICS \n",
    "# confusion_matrix = computeCM(y_test, y_hat) \n",
    "# print(confusion_matrix) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
