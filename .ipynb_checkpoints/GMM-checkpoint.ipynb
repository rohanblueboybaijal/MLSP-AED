{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065a0558-1a85-4a78-8e29-cf9babd4f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from audio_proc_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86ad3c7-ca28-4d9d-a333-7270ce7faa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1.5, 2.5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[0,1,2,],[1,2,3]])\n",
    "A.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6255aeef-c623-479c-80a2-f373e4f68077",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs= 16000\n",
    "n_mfcc = 20\n",
    "\n",
    "# Read audio\n",
    "x_music = readDir('music_speech/music_wav', Fs)    #change it as per your directory\n",
    "x_speech = readDir('music_speech/speech_wav', Fs)  #change it as per your directory\n",
    "x_silence = readDir('music_speech/silence_wav', Fs)\n",
    "X = np.concatenate((x_music, x_speech, x_silence))\n",
    "\n",
    "# Create labels\n",
    "y_music = np.array([[1,0,0]]*len(x_music))\n",
    "y_speech = np.array([[0,1,0]]*len(x_speech))\n",
    "y_silence = np.array([[0,0,1]]*len(x_silence))\n",
    "Y = np.concatenate((y_music, y_speech, y_silence))\n",
    "\n",
    "X_train, y_train, X_test, y_test = splitData(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d86bf33-84e9-4c72-96e6-acb414762b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = audio2mfcc(X_train, n_mfcc, Fs)    # x_train: (Nclips, N_mfcc, N_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e59d903-d9ab-40b5-8b79-6224901f5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[0, :,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a371b9-b195-460d-93e8-8c200cf8ea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =  np.transpose(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d42aa9b-a918-4375-bc19-79fd5fefe889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_row = np.random.randint(low=0, high=313, size=5)\n",
    "mu = [  X[row_index,:] for row_index in random_row ]\n",
    "len(mu)\n",
    "sigma = [ np.cov(X.T) for _ in range(5) ]\n",
    "\n",
    "sigma[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81b56e4c-e21a-4161-b0d5-377f1f846a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, k, max_iter=10):\n",
    "        '''\n",
    "            k : Number of latent variables\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.max_iter = int(max_iter)\n",
    "    \n",
    "    def initialize(self, X):\n",
    "        '''\n",
    "            n : number of training examples\n",
    "            m : number of features in each example\n",
    "        '''\n",
    "        self.shape = X.shape\n",
    "        self.n, self.m = self.shape\n",
    "    \n",
    "        # Pi contains the prior probability of latent variables\n",
    "        self.Pi = np.full(shape=self.k, fill_value=1/self.k)\n",
    "        \n",
    "        # P(x_i, k)/ P(x_i)\n",
    "        self.weights = np.full( shape=(self.n, self.k), fill_value=1/self.k) # n x k\n",
    "        \n",
    "        # Each mu is randomly selected as one of the data points\n",
    "        random_row = np.random.randint(low=0, high=self.n, size=self.k)\n",
    "        self.mu = [  X[row_index,:] for row_index in random_row ]\n",
    "        \n",
    "        # Each class is given the same covariance for initialization\n",
    "        self.sigma = [ np.cov(X.T) for _ in range(self.k) ]\n",
    "    \n",
    "    def E_step(self, X):\n",
    "        # E-Step: update weights and phi holding mu and sigma constant\n",
    "        self.weights = self.predict_proba(X)\n",
    "        self.Pi = self.weights.mean(axis=0) # collapses the rows to give vector of size 1 x k\n",
    "        \n",
    "        # Pi_k = N_k^{soft} / N\n",
    "        \n",
    "    def M_step(self, X):\n",
    "        # Now the weights are held constant and mu and sigma is updated\n",
    "        for i in range(self.k):\n",
    "            weight = self.weights[:, i]\n",
    "            total_weight = weight.sum()\n",
    "            self.mu = (X * weight).sum(axis=0) / total_weight\n",
    "            self.sigma[i] = np.cov(X.T, aweights=(weight/total_weight).flatten(), bias=True)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.initialize(X)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            self.E_step(X)\n",
    "            self.M_step(X)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        # likelihood is of shape (n x k). Relate it to r_nk\n",
    "        likelihood = np.zeros( (self.n, self.k) )\n",
    "        for i in range(self.k):\n",
    "            # row of X is considered as 1 training example\n",
    "            distribution = multivariate_normal(mean=self.mu[i], cov=self.sigma[i])\n",
    "            likelihood[:,i] = distribution.pdf(X)\n",
    "\n",
    "        # makes use of broadcasting - so the i-th column is multiplied by P(i) only\n",
    "        numerator = likelihood * self.Pi # (n x k)\n",
    "        denominator = numerator.sum(axis=1)[:, np.newaxis] # (n x 1)\n",
    "        weights = numerator / denominator # (n x k)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d0ceabf-cd34-440d-ba71-fb7aa9a1419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a073736-153a-42d6-9076-826b54347c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.initialize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adedc9f5-565d-4cb3-a726-f6bdec3cebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 1)\n",
      "(313, 5)\n"
     ]
    }
   ],
   "source": [
    "w = gmm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1f1d85b-c40a-4337-9647-0db59340c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.4, 0.6, 0.8, 1. ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([1,2,3,4,5])\n",
    "A*gmm.Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f05c78fc-690e-41f8-86cb-ef42459dd92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 20)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.weights.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
